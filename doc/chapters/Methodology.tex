\chapter{Methodology}

We used the \textit{zero-shot} method \cite{mitchell2023detectgpt}, that is  a way of detecting machine-generated text without using any labeled data or fine-tuning. It uses only the raw log probabilities computed by a generative model to determine if a candidate passage was sampled from it.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\linewidth]{images/plagiarized_paper_diagram}
	\caption{System's inner workings}
	\label{fig:plagiarizedpaperdiagram}
\end{figure}

The zero-shot method designed by Eric Mitchell et al. is called \textit{DetectGPT}. It's based on the hypothesis that samples from a source model typically lie in areas of negative curvature of the log probability function of the model, unlike human text. DetectGPT introduces random perturbations to the wording in a text sample and uses the changes in likelihood under an LLM as a discriminative signal.

\paragraph{How it works}
The system works as follows: it applies $N$ perturbations to the input text --- a perturbation is generated by making a encoder-decoder model, such as \textit{T5}, slightly rephrase the input text ---, it computes their log probability and computes a final metric, described by Formula \ref{formula:logprobmetric} that is compared to a certain $\varepsilon$ to determine if the input is from a GPT model.

\begin{figure}[H]
	\centering
	\label{formula:logprobmetric}
	\begin{equation}
		\dfrac{1}{N} \sum_{i = 0}^{N}
		\log\left(
		\dfrac{p(x)}{p(\tilde{x_i})}
		\right)
		\stackrel{?}{>}
		\varepsilon
	\end{equation}
\end{figure}

\paragraph{Drawbacks}
Another assumption of is that we have a reasonable way to perturb the text and see how the probabilities change, we used \textit{T5} but some domains may have lower performance if this model doesn't capture the space of meaningful rephrases well, affecting the quality of the curvature estimate. Another problem is that the system is more computationally expensive than other detection methods, as it needs to sample and score the set of perturbations for each candidate passage, instead of just the candidate passage; a better way to perturb the text or estimate the curvature more efficiently may help reduce these costs.

\paragraph{News article}
Currently, it seems this system is the state-of-the-art for detecting GPT-generated texts \cite{state-of-the-art-article}.