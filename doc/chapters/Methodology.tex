\chapter{Methodology}
\label{chapter:meth}

\section{Theoretical background}

We used the \textit{zero-shot} method \cite{mitchell2023detectgpt}, that is  a way of detecting machine-generated text without using any labeled data or fine-tuning. It uses only the raw log probabilities computed by a generative model to determine if a candidate passage was sampled from it.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\linewidth]{images/Methodology/plagiarized_paper_diagram}
	\caption{System's inner workings}
	\label{fig:plagiarizedpaperdiagram}
\end{figure}

\paragraph{Log probabilities}
They are the metric used by OpenAI's \textit{ChatGPT} to measure the likelihood of different tokens or completions to be used by their model.

\paragraph{}
The zero-shot method is designed by Eric Mitchell et al. and is called \textit{DetectGPT}. It's based on the hypothesis that samples from a source model typically lie in areas of negative curvature of the log probability function of the model --- that is perturbations from a  GPT-generated text   have similar log probabilities ---, unlike human text where their perturbations' log probabilities are different. DetectGPT introduces random perturbations to the wording in a text sample and uses the changes in likelihood under an LLM as a discriminative signal.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\linewidth]{images/Methodology/plagiarized_paper_graph.pdf}
	\caption{How different perturbations' log probs lie in space}
	\label{fig:plagiarizedgraph}
\end{figure}

\paragraph{Encoder-decoder model}
It's a type of neural network that learned to map an input sequence to an output sequence. \textit{T5} is a specific encoder-decoder model that can handle various natural language processing tasks by converting them into a text-to-text format. In our use-case, T5 removes parts of an input text and replaces them with generated tokens to produce in output a rephrase of the input.

\paragraph{How it works}
The system works as follows: it applies $N$ perturbations to the input text --- a perturbation is generated by making a encoder-decoder model, such as \textit{T5}, slightly rephrase the input text ---, it computes their log probability and computes a final metric, described by Formula \ref{formula:logprobmetric} that is compared to a certain $\varepsilon$ to determine if the input is from a GPT model.

\begin{figure}[H]
	\centering
	\label{formula:logprobmetric}
	\begin{equation}
		\dfrac{1}{N} \sum_{i = 0}^{N}
		\log\left(
		\dfrac{p(x)}{p(\tilde{x_i})}
		\right)
		\stackrel{?}{>}
		\varepsilon
	\end{equation}
\end{figure}

\paragraph{News article}
Currently, it seems this system might be the state-of-the-art for detecting GPT-generated texts \cite{state-of-the-art-article}.

\section{Drawbacks}

An assumption made is that we have a reasonable way to perturb the text and see how the probabilities change. We used \textit{T5} but some domains may have lower performance if this model doesn't capture the space of meaningful rephrases well, affecting the quality of the curvature estimate. Another problem is that the system is more computationally expensive than other detection methods, as it needs to sample and score the set of perturbations for each candidate passage, instead of just the candidate passage; a better way to perturb the text or estimate the curvature more efficiently may help reduce these costs.

It's also to be noted that the system may not be able to properly detect texts generated by other \textit{large language models} different than the one used to compute the log probabilities, in our implementation GPT-3.